{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json#format texte dérivé de la notation objets de JavaScript, données structurées en paires clés/valeurs\n"
      ],
      "metadata": {
        "id": "HSZZAztWNcDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9Dzl-tthMos"
      },
      "source": [
        "*Fonction* Pour Lire le CoNLLu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3Kf_gFHhOsX"
      },
      "outputs": [],
      "source": [
        "def lire_conllu(fichier):#fonction pour analyser le texte au format coNLL-U\n",
        "\n",
        "    fichier_input=open(fichier,mode='r',encoding='utf8')#ouvre le fichier en mode lecture avec encodage UTF-8\n",
        "    contenu=fichier_input.readlines()#lit toutes les lignes du fichier et les stocke dans une liste\n",
        "    fichier_input.close()#ferme le fichier pour libérer les ressources\n",
        "\n",
        "    phrases = []#liste vide pour stocker les phrases analysées\n",
        "    phrase_actuelle = []#liste temporaire pour stocker les tokens d'une phrase en cours\n",
        "\n",
        "    for ligne in contenu:#parcourt chaque ligne du fichier\n",
        "        ligne = ligne.strip()#supprime les espaces inutiles et les sauts de ligne\n",
        "        if ligne.startswith(\"#\") or ligne == \"\":#ignore les commentaires et les lignes vides\n",
        "            if phrase_actuelle: #si une phrase en cours existe\n",
        "                phrases.append(phrase_actuelle)#ajout de la phrase à la liste phrases\n",
        "                phrase_actuelle = []#réinitialise phrase_actuelle pour commencer une nouvelle phrase\n",
        "            continue#ignore le reste de l'itération, passe à la ligne suivante\n",
        "\n",
        "        colonnes = ligne.split(\"\\t\")#divise la ligne en colonnes\n",
        "        if len(colonnes) >= 4:#vérifie que la ligne contient 4 colonnes\n",
        "            token = {#dictionnaire pour représenter un mot\n",
        "                'id': colonnes[0],#identifiant, numéro de découpage des tokens\n",
        "                'forme': colonnes[1],#forme de surface\n",
        "                'lemme': colonnes[2],#lemme\n",
        "                'classgr': colonnes[3],#partie du discours\n",
        "                }\n",
        "            phrase_actuelle.append(token)#ajoute le token à la liste\n",
        "\n",
        "    if phrase_actuelle:#vérifie s'il reste une phrase non ajoutée après la boucle\n",
        "        phrases.append(phrase_actuelle)#ajoute la dernière phrase à la liste des phrases\n",
        "    print (str(phrases))#affiche la liste des phrases analysées\n",
        "\n",
        "    return phrases#retourne la liste de toutes les phrases analysées\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clsvkp3ZqaB-"
      },
      "source": [
        "FONCTION POUR COMPTER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXUOaLksqSxl"
      },
      "outputs": [],
      "source": [
        "def statistiques(phrases):#fonction pour calculer des statistiques à partir d'un ensemble de phrases, où chaque phrase = liste de tokens\n",
        "\n",
        "    ngramMinLength = int(input (\"Taille minimale des n-grammes: \"))#demande à l'utilisateur la taille minimale des n-grammes\n",
        "    ngramMaxLength = int(input (\"Taille maximale des n-grammes: \"))# demande à l'utilisateur la taille maximale des n-grammes\n",
        "\n",
        "    nbSents = len(phrases)#calcule le nombre total de phrases\n",
        "    nbToks = 0#initialise le compteur pour le nombre total de tokens\n",
        "    nbForms = 0#pour le nombre de formes\n",
        "    nbPuncts = 0#pour le nombre de tokens ponctuation\n",
        "\n",
        "    totalLength = 0#initialise le total des longueurs des formes pour calculer la longueur moyenne\n",
        "\n",
        "    noun_freq = {}#initialise un dictionnaire pour stocker la fréquence des noms\n",
        "    verb_freq = {}#fréquence des verbes\n",
        "    adj_freq = {}#fréquence des adjectifs\n",
        "    adv_freq = {}#fréquence des adverbes\n",
        "    lem_freq = {}#fréquence des lemmes\n",
        "    unique_lemmes = set()#ensemble pour stocker les lemmes uniques\n",
        "    ngrams = {}#initialise un dictionnaire pour stocker les n-grammes\n",
        "    sauter = False#initialise une variable pour ignorer certains tokens invalides\n",
        "\n",
        "\n",
        "    for phrase in phrases:#parcourt chaque phrase de la liste phrase\n",
        "        for token in phrase:#parcourt chaque token de la phrase actuelle\n",
        "            nbToks += 1#incrémente le compteur de tokens pour chaque token rencontré\n",
        "            if token['classgr'] == 'SYM' or token['classgr'] == 'X' or sauter:#vérifie si le token est à ignorer\n",
        "                sauter = False # réinitialise la variable pour ignorer les prochains tokens si nécessaire\n",
        "                continue#passe au token suivant\n",
        "            else:#pour tous les autres types de tokens\n",
        "                if token['classgr'] == 'PUNCT':#si le token est une ponctuation\n",
        "                    nbPuncts += 1#incrémente le compteur de ponctuations\n",
        "                else:#sinon le token est une forme\n",
        "\n",
        "                    if \"-\" not in token['id']:#vérifie que le token n'est pas un mot composé\n",
        "                        nbForms += 1 #incrémente le compteur de formes\n",
        "                        totalLength += len(token['forme'])#ajoute la longueur de la forme au total\n",
        "                    else:\n",
        "                        sauter = True#active l'indicateur pour ignorer le token\n",
        "                    unique_lemmes.add(token['lemme'])#ajoute le lemme à l'ensemble des lemmes uniques\n",
        "                    lem_freq[token['lemme']] = lem_freq.get(token['lemme'], 0) + 1#met à jour la fréquence du lemme\n",
        "\n",
        "                    if token['classgr'] == 'NOUN':#si le token est un nom\n",
        "                        noun_freq[token['forme']] = noun_freq.get(token['forme'], 0) + 1#met à jour la fréquence du nom\n",
        "                    elif token['classgr'] == 'VERB':#si le token est un verbe\n",
        "                        verb_freq[token['forme']] = verb_freq.get(token['forme'], 0) + 1#met à jour la fréquence du verbe\n",
        "                    elif token['classgr'] == 'ADJ':#si le token est un adjectif\n",
        "                        adj_freq[token['forme']] = adj_freq.get(token['forme'], 0) + 1#met à jour la fréquence de l'adjectif\n",
        "                    elif token['classgr'] == 'ADV':#si le token est un adverbe\n",
        "                        adv_freq[token['forme']] = adv_freq.get(token['forme'], 0) + 1#met à jour la fréquence de l'adverbe\n",
        "\n",
        "    for n in range(ngramMinLength, ngramMaxLength + 1):#boucle sur chaque taille d'n-grammes\n",
        "        freq_ngram = {}#initialise un dictionnaire pour stocker les fréquences des n-grammes\n",
        "        for sentence in phrases:#boucle sur chaque phrase\n",
        "            tokens = [token['forme']for token in sentence if token['classgr'] != 'PUNCT' and token['classgr'] != 'SYM' and token['classgr'] != 'X']#extrait les formes non ignorées\n",
        "            for i in range(0,len(tokens) - n + 1):#boucle sur les n-grammes possibles dans la phrase\n",
        "                ngram = tuple(tokens[i:i + n])#crée un n-gramme de taille n\n",
        "                freq_ngram[ngram] = freq_ngram.get(ngram, 0) + 1#met à jour la fréquence du n-gramme\n",
        "        ngrams[n] = sorted(freq_ngram.items(), key=lambda x: x[1], reverse=True)#trie les n-grammes par fréquence décroissante\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    nbTypes = len(unique_lemmes)#calcule le nombre de types uniques (lemmes uniques)\n",
        "\n",
        "\n",
        "# trie les noms, verbes, adjectifs, adverbes, lemmes par fréquence décroissante\n",
        "    noun2freq = sorted(noun_freq.items(), key=lambda x: x[1], reverse=True)\n",
        "    verb2freq = sorted(verb_freq.items(), key=lambda x: x[1], reverse=True)\n",
        "    adj2freq = sorted(adj_freq.items(), key=lambda x: x[1], reverse=True)\n",
        "    adv2freq = sorted(adv_freq.items(), key=lambda x: x[1], reverse=True)\n",
        "    lem2freq = sorted(lem_freq.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "\n",
        "    averageFormLength = totalLength / nbForms#calcule la longueur moyenne des formes\n",
        "    averageSentLength = nbForms / nbSents#calcule la longueur moyenne des phrases\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return { #retourne les statistiques sous forme de dictionnaire\n",
        "        'nbsents': nbSents,\n",
        "        'nbToks': nbToks,\n",
        "        'nbForms': nbForms,\n",
        "        'nbPuncts': nbPuncts,\n",
        "        'noun2freq': noun2freq,\n",
        "        'verb2freq': verb2freq,\n",
        "        'adj2freq': adj2freq,\n",
        "        'adv2freq': adv2freq,\n",
        "        'lem2freq': lem2freq,\n",
        "        'nbTypes': len(unique_lemmes),\n",
        "        'averageFormLength': averageFormLength,\n",
        "        'averageSentLength': averageSentLength,\n",
        "        'ngrams': ngrams\n",
        "    }\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiKxq8fwg0YG"
      },
      "source": [
        "Tester fonction et Générer .JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH01oxjSzrUk",
        "outputId": "ca0c7256-5147-4c16-e2dd-d1aa0d3cf6ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[{'id': '1', 'forme': 'Clarence', 'lemme': 'Clarence', 'classgr': 'PROPN'}, {'id': '2', 'forme': 'était', 'lemme': 'être', 'classgr': 'AUX'}, {'id': '3', 'forme': 'lumineux', 'lemme': 'lumineux', 'classgr': 'ADJ'}, {'id': '4', 'forme': ',', 'lemme': ',', 'classgr': 'PUNCT'}, {'id': '5', 'forme': 'et', 'lemme': 'et', 'classgr': 'CCONJ'}, {'id': '6', 'forme': 'rester', 'lemme': 'rester', 'classgr': 'VERB'}, {'id': '7', 'forme': 'près', 'lemme': 'près', 'classgr': 'ADV'}, {'id': '8', 'forme': 'de', 'lemme': 'de', 'classgr': 'ADP'}, {'id': '9', 'forme': 'lui', 'lemme': 'lui', 'classgr': 'PRON'}, {'id': '10', 'forme': \"m'\", 'lemme': 'moi', 'classgr': 'PRON'}, {'id': '11', 'forme': 'offrait', 'lemme': 'offrir', 'classgr': 'VERB'}, {'id': '12', 'forme': 'de', 'lemme': 'de', 'classgr': 'ADP'}, {'id': '13', 'forme': 'la', 'lemme': 'le', 'classgr': 'DET'}, {'id': '14', 'forme': 'lumière', 'lemme': 'lumière', 'classgr': 'NOUN'}, {'id': '15', 'forme': '.', 'lemme': '.', 'classgr': 'PUNCT'}], [{'id': '1', 'forme': \"Qu'\", 'lemme': 'que', 'classgr': 'SCONJ'}, {'id': '2', 'forme': 'il', 'lemme': 'lui', 'classgr': 'PRON'}, {'id': '3', 'forme': 'décide', 'lemme': 'décider', 'classgr': 'VERB'}, {'id': '4', 'forme': 'pour', 'lemme': 'pour', 'classgr': 'ADP'}, {'id': '5', 'forme': 'nous', 'lemme': 'nous', 'classgr': 'PRON'}, {'id': '6', 'forme': 'tous', 'lemme': 'tout', 'classgr': 'PRON'}, {'id': '7', 'forme': ',', 'lemme': ',', 'classgr': 'PUNCT'}, {'id': '8', 'forme': 'que', 'lemme': 'que', 'classgr': 'SCONJ'}, {'id': '9', 'forme': 'sa', 'lemme': 'son', 'classgr': 'DET'}, {'id': '10', 'forme': 'voix', 'lemme': 'voix', 'classgr': 'NOUN'}, {'id': '11', 'forme': 'porte', 'lemme': 'porter', 'classgr': 'VERB'}, {'id': '12', 'forme': 'toujours', 'lemme': 'toujours', 'classgr': 'ADV'}, {'id': '13', 'forme': 'plus', 'lemme': 'plus', 'classgr': 'ADV'}, {'id': '14', 'forme': 'que', 'lemme': 'que', 'classgr': 'SCONJ'}, {'id': '15', 'forme': 'la', 'lemme': 'le', 'classgr': 'DET'}, {'id': '16', 'forme': 'nôtre', 'lemme': 'nôtre', 'classgr': 'PRON'}, {'id': '17', 'forme': 'ne', 'lemme': 'ne', 'classgr': 'ADV'}, {'id': '18', 'forme': 'me', 'lemme': 'moi', 'classgr': 'PRON'}, {'id': '19', 'forme': 'dérangeait', 'lemme': 'déranger', 'classgr': 'VERB'}, {'id': '20', 'forme': 'pas', 'lemme': 'pas', 'classgr': 'ADV'}, {'id': '21', 'forme': ',', 'lemme': ',', 'classgr': 'PUNCT'}, {'id': '22', 'forme': 'à', 'lemme': 'à', 'classgr': 'ADP'}, {'id': '23', 'forme': \"l'\", 'lemme': 'le', 'classgr': 'DET'}, {'id': '24', 'forme': 'époque', 'lemme': 'époque', 'classgr': 'NOUN'}, {'id': '25', 'forme': '.', 'lemme': '.', 'classgr': 'PUNCT'}], [{'id': '1', 'forme': 'Je', 'lemme': 'moi', 'classgr': 'PRON'}, {'id': '2', 'forme': 'répète', 'lemme': 'répéter', 'classgr': 'VERB'}, {'id': '3', 'forme': ':', 'lemme': ':', 'classgr': 'PUNCT'}, {'id': '4', 'forme': 'Clarence', 'lemme': 'Clarence', 'classgr': 'PROPN'}, {'id': '5', 'forme': 'était', 'lemme': 'être', 'classgr': 'AUX'}, {'id': '6', 'forme': 'lumineux', 'lemme': 'lumineux', 'classgr': 'ADJ'}, {'id': '7', 'forme': '.', 'lemme': '.', 'classgr': 'PUNCT'}], [{'id': '1', 'forme': 'À', 'lemme': 'à', 'classgr': 'ADP'}, {'id': '2', 'forme': 'mes', 'lemme': 'son', 'classgr': 'DET'}, {'id': '3', 'forme': 'yeux', 'lemme': 'œil', 'classgr': 'NOUN'}, {'id': '4', 'forme': ',', 'lemme': ',', 'classgr': 'PUNCT'}, {'id': '5', 'forme': 'il', 'lemme': 'lui', 'classgr': 'PRON'}, {'id': '6', 'forme': 'avait', 'lemme': 'avoir', 'classgr': 'VERB'}, {'id': '7', 'forme': 'plus', 'lemme': 'plus', 'classgr': 'ADV'}, {'id': '8', 'forme': 'de', 'lemme': 'de', 'classgr': 'ADP'}, {'id': '9', 'forme': 'puissance', 'lemme': 'puissance', 'classgr': 'NOUN'}, {'id': '10', 'forme': ',', 'lemme': ',', 'classgr': 'PUNCT'}, {'id': '11', 'forme': 'plus', 'lemme': 'plus', 'classgr': 'ADV'}, {'id': '12', 'forme': 'de', 'lemme': 'de', 'classgr': 'ADP'}, {'id': '13', 'forme': 'talent', 'lemme': 'talent', 'classgr': 'NOUN'}, {'id': '14', 'forme': ',', 'lemme': ',', 'classgr': 'PUNCT'}, {'id': '15', 'forme': 'et', 'lemme': 'et', 'classgr': 'CCONJ'}, {'id': '16', 'forme': 'le', 'lemme': 'le', 'classgr': 'DET'}, {'id': '17', 'forme': 'côtoyer', 'lemme': 'côtoyer', 'classgr': 'NOUN'}, {'id': '18', 'forme': 'me', 'lemme': 'moi', 'classgr': 'PRON'}, {'id': '19', 'forme': 'donnait', 'lemme': 'donner', 'classgr': 'VERB'}, {'id': '20', 'forme': 'toute', 'lemme': 'tout', 'classgr': 'ADJ'}, {'id': '21', 'forme': \"l'\", 'lemme': 'le', 'classgr': 'DET'}, {'id': '22', 'forme': 'importance', 'lemme': 'importance', 'classgr': 'NOUN'}, {'id': '23', 'forme': 'que', 'lemme': 'que', 'classgr': 'PRON'}, {'id': '24', 'forme': 'je', 'lemme': 'moi', 'classgr': 'PRON'}, {'id': '25', 'forme': \"n'\", 'lemme': 'ne', 'classgr': 'ADV'}, {'id': '26', 'forme': 'avais', 'lemme': 'avoir', 'classgr': 'AUX'}, {'id': '27', 'forme': 'encore', 'lemme': 'encore', 'classgr': 'ADV'}, {'id': '28', 'forme': 'jamais', 'lemme': 'jamais', 'classgr': 'ADV'}, {'id': '29', 'forme': 'eue', 'lemme': 'avoir', 'classgr': 'VERB'}, {'id': '30', 'forme': '.', 'lemme': '.', 'classgr': 'PUNCT'}], [{'id': '1', 'forme': 'Il', 'lemme': 'lui', 'classgr': 'PRON'}, {'id': '2', 'forme': \"m'\", 'lemme': 'moi', 'classgr': 'PRON'}, {'id': '3', 'forme': 'a', 'lemme': 'avoir', 'classgr': 'AUX'}, {'id': '4', 'forme': 'grondée', 'lemme': 'gronder', 'classgr': 'VERB'}, {'id': '5', 'forme': 'de', 'lemme': 'de', 'classgr': 'ADP'}, {'id': '6', 'forme': '%', 'lemme': '%', 'classgr': 'SYM'}, {'id': '7', 'forme': '&', 'lemme': '&', 'classgr': 'SYM'}, {'id': '8', 'forme': '*', 'lemme': '*', 'classgr': 'X'}, {'id': '9', 'forme': '@', 'lemme': '@', 'classgr': 'PUNCT'}, {'id': '10', 'forme': '#', 'lemme': '#', 'classgr': 'X'}, {'id': '11', 'forme': '@', 'lemme': '@', 'classgr': 'PUNCT'}, {'id': '12', 'forme': 'Clarence', 'lemme': 'Clarence', 'classgr': 'PROPN'}, {'id': '13', 'forme': ',', 'lemme': ',', 'classgr': 'PUNCT'}, {'id': '14-15', 'forme': 'au', 'lemme': '_', 'classgr': '_'}, {'id': '14', 'forme': 'à', 'lemme': 'à', 'classgr': 'ADP'}, {'id': '15', 'forme': 'le', 'lemme': 'le', 'classgr': 'DET'}, {'id': '16', 'forme': 'sortir', 'lemme': 'sortir', 'classgr': 'NOUN'}, {'id': '17', 'forme': 'de', 'lemme': 'de', 'classgr': 'ADP'}, {'id': '18', 'forme': \"l'\", 'lemme': 'le', 'classgr': 'DET'}, {'id': '19', 'forme': 'enfance', 'lemme': 'enfance', 'classgr': 'NOUN'}, {'id': '20', 'forme': ',', 'lemme': ',', 'classgr': 'PUNCT'}, {'id': '21', 'forme': 'avait', 'lemme': 'avoir', 'classgr': 'VERB'}, {'id': '22', 'forme': 'un', 'lemme': 'un', 'classgr': 'DET'}, {'id': '23', 'forme': 'pouvoir', 'lemme': 'pouvoir', 'classgr': 'NOUN'}, {'id': '24', 'forme': 'dont', 'lemme': 'dont', 'classgr': 'PRON'}, {'id': '25', 'forme': 'aucun', 'lemme': 'aucun', 'classgr': 'PRON'}, {'id': '26', 'forme': 'de', 'lemme': 'de', 'classgr': 'ADP'}, {'id': '27', 'forme': 'nous', 'lemme': 'nous', 'classgr': 'PRON'}, {'id': '28', 'forme': \"n'\", 'lemme': 'ne', 'classgr': 'ADV'}, {'id': '29', 'forme': 'avait', 'lemme': 'avoir', 'classgr': 'VERB'}, {'id': '30', 'forme': 'conscience', 'lemme': 'conscience', 'classgr': 'NOUN'}, {'id': '31', 'forme': ',', 'lemme': ',', 'classgr': 'PUNCT'}, {'id': '32', 'forme': 'le', 'lemme': 'le', 'classgr': 'DET'}, {'id': '33', 'forme': 'pouvoir', 'lemme': 'pouvoir', 'classgr': 'NOUN'}, {'id': '34', 'forme': 'joyeux', 'lemme': 'joyeux', 'classgr': 'ADJ'}, {'id': '35', 'forme': 'et', 'lemme': 'et', 'classgr': 'CCONJ'}, {'id': '36', 'forme': 'trompeur', 'lemme': 'trompeur', 'classgr': 'ADJ'}, {'id': '37', 'forme': 'de', 'lemme': 'de', 'classgr': 'ADP'}, {'id': '38', 'forme': 'nous', 'lemme': 'nous', 'classgr': 'PRON'}, {'id': '39', 'forme': 'rendre', 'lemme': 'rendre', 'classgr': 'VERB'}, {'id': '40', 'forme': 'plus', 'lemme': 'plus', 'classgr': 'ADV'}, {'id': '41', 'forme': 'beaux', 'lemme': 'beau', 'classgr': 'ADJ'}, {'id': '42', 'forme': \"qu'\", 'lemme': 'que', 'classgr': 'SCONJ'}, {'id': '43', 'forme': 'on', 'lemme': 'on', 'classgr': 'PRON'}, {'id': '44', 'forme': 'ne', 'lemme': 'ne', 'classgr': 'ADV'}, {'id': '45', 'forme': \"l'\", 'lemme': 'lui', 'classgr': 'PRON'}, {'id': '46', 'forme': 'était', 'lemme': 'être', 'classgr': 'AUX'}, {'id': '47', 'forme': ',', 'lemme': ',', 'classgr': 'PUNCT'}, {'id': '48', 'forme': 'de', 'lemme': 'de', 'classgr': 'ADP'}, {'id': '49', 'forme': 'se', 'lemme': 'soi', 'classgr': 'PRON'}, {'id': '50', 'forme': 'rendre', 'lemme': 'rendre', 'classgr': 'VERB'}, {'id': '51', 'forme': 'meilleur', 'lemme': 'meilleur', 'classgr': 'ADJ'}, {'id': '52', 'forme': \"qu'\", 'lemme': 'que', 'classgr': 'SCONJ'}, {'id': '53', 'forme': 'il', 'lemme': 'lui', 'classgr': 'PRON'}, {'id': '54', 'forme': 'ne', 'lemme': 'ne', 'classgr': 'ADV'}, {'id': '55', 'forme': \"l'\", 'lemme': 'lui', 'classgr': 'PRON'}, {'id': '56', 'forme': 'était', 'lemme': 'être', 'classgr': 'AUX'}, {'id': '57', 'forme': '.', 'lemme': '.', 'classgr': 'PUNCT'}], [{'id': '1', 'forme': 'Il', 'lemme': 'lui', 'classgr': 'PRON'}, {'id': '2', 'forme': 'suffisait', 'lemme': 'suffiser', 'classgr': 'VERB'}, {'id': '3', 'forme': \"qu'\", 'lemme': 'que', 'classgr': 'SCONJ'}, {'id': '4', 'forme': 'il', 'lemme': 'lui', 'classgr': 'PRON'}, {'id': '5', 'forme': 'te', 'lemme': 'toi', 'classgr': 'PRON'}, {'id': '6', 'forme': 'regarde', 'lemme': 'regarder', 'classgr': 'VERB'}, {'id': '7', 'forme': 'avec', 'lemme': 'avec', 'classgr': 'ADP'}, {'id': '8', 'forme': 'intensité', 'lemme': 'intensité', 'classgr': 'NOUN'}, {'id': '9', 'forme': ',', 'lemme': ',', 'classgr': 'PUNCT'}, {'id': '10', 'forme': 'acquiesce', 'lemme': 'acquiescer', 'classgr': 'VERB'}, {'id': '11', 'forme': 'à', 'lemme': 'à', 'classgr': 'ADP'}, {'id': '12', 'forme': 'une', 'lemme': 'un', 'classgr': 'PRON'}, {'id': '13', 'forme': 'de', 'lemme': 'de', 'classgr': 'ADP'}, {'id': '14', 'forme': 'tes', 'lemme': 'son', 'classgr': 'DET'}, {'id': '15', 'forme': 'réflexions', 'lemme': 'réflexion', 'classgr': 'NOUN'}, {'id': '16', 'forme': ',', 'lemme': ',', 'classgr': 'PUNCT'}, {'id': '17', 'forme': 'se', 'lemme': 'soi', 'classgr': 'PRON'}, {'id': '18', 'forme': 'marre', 'lemme': 'marrer', 'classgr': 'VERB'}, {'id': '19', 'forme': 'à', 'lemme': 'à', 'classgr': 'ADP'}, {'id': '20', 'forme': 'une', 'lemme': 'un', 'classgr': 'PRON'}, {'id': '21', 'forme': 'de', 'lemme': 'de', 'classgr': 'ADP'}, {'id': '22', 'forme': 'tes', 'lemme': 'son', 'classgr': 'DET'}, {'id': '23', 'forme': 'vannes', 'lemme': 'vanne', 'classgr': 'NOUN'}, {'id': '24', 'forme': ',', 'lemme': ',', 'classgr': 'PUNCT'}, {'id': '25', 'forme': 'et', 'lemme': 'et', 'classgr': 'CCONJ'}, {'id': '26', 'forme': 'tu', 'lemme': 'toi', 'classgr': 'PRON'}, {'id': '27', 'forme': 'étais', 'lemme': 'être', 'classgr': 'AUX'}, {'id': '28', 'forme': 'le', 'lemme': 'le', 'classgr': 'DET'}, {'id': '29', 'forme': 'roi', 'lemme': 'roi', 'classgr': 'NOUN'}, {'id': '30-31', 'forme': 'du', 'lemme': '_', 'classgr': '_'}, {'id': '30', 'forme': 'de', 'lemme': 'de', 'classgr': 'ADP'}, {'id': '31', 'forme': 'le', 'lemme': 'le', 'classgr': 'DET'}, {'id': '32', 'forme': 'monde', 'lemme': 'monde', 'classgr': 'NOUN'}, {'id': '33', 'forme': '.', 'lemme': '.', 'classgr': 'PUNCT'}], [{'id': '1', 'forme': 'Je', 'lemme': 'moi', 'classgr': 'PRON'}, {'id': '2', 'forme': \"n'\", 'lemme': 'ne', 'classgr': 'ADV'}, {'id': '3', 'forme': 'étais', 'lemme': 'être', 'classgr': 'AUX'}, {'id': '4', 'forme': 'pas', 'lemme': 'pas', 'classgr': 'ADV'}, {'id': '5', 'forme': 'la', 'lemme': 'le', 'classgr': 'DET'}, {'id': '6', 'forme': 'seule', 'lemme': 'seul', 'classgr': 'ADJ'}, {'id': '7', 'forme': '.', 'lemme': '.', 'classgr': 'PUNCT'}], [{'id': '1', 'forme': 'Mais', 'lemme': 'mais', 'classgr': 'CCONJ'}, {'id': '2', 'forme': ',', 'lemme': ',', 'classgr': 'PUNCT'}, {'id': '3', 'forme': 'persuadée', 'lemme': 'persuader', 'classgr': 'VERB'}, {'id': '4', 'forme': \"d'\", 'lemme': 'de', 'classgr': 'ADP'}, {'id': '5', 'forme': 'avoir', 'lemme': 'avoir', 'classgr': 'VERB'}, {'id': '6', 'forme': 'un', 'lemme': 'un', 'classgr': 'DET'}, {'id': '7', 'forme': 'statut', 'lemme': 'statut', 'classgr': 'NOUN'}, {'id': '8', 'forme': 'à', 'lemme': 'à', 'classgr': 'ADP'}, {'id': '9', 'forme': 'part', 'lemme': 'part', 'classgr': 'NOUN'}, {'id': '10', 'forme': ',', 'lemme': ',', 'classgr': 'PUNCT'}, {'id': '11', 'forme': 'je', 'lemme': 'moi', 'classgr': 'PRON'}, {'id': '12', 'forme': 'rayonnais', 'lemme': 'rayonner', 'classgr': 'VERB'}, {'id': '13', 'forme': 'plus', 'lemme': 'plus', 'classgr': 'ADV'}, {'id': '14', 'forme': 'que', 'lemme': 'que', 'classgr': 'SCONJ'}, {'id': '15', 'forme': 'tout', 'lemme': 'tout', 'classgr': 'ADJ'}, {'id': '16', 'forme': 'le', 'lemme': 'le', 'classgr': 'DET'}, {'id': '17', 'forme': 'monde', 'lemme': 'monde', 'classgr': 'NOUN'}, {'id': '18', 'forme': 'sous', 'lemme': 'sous', 'classgr': 'ADP'}, {'id': '19', 'forme': 'son', 'lemme': 'son', 'classgr': 'DET'}, {'id': '20', 'forme': 'amitié', 'lemme': 'amitié', 'classgr': 'NOUN'}, {'id': '21', 'forme': '.', 'lemme': '.', 'classgr': 'PUNCT'}], [{'id': '1', 'forme': 'Une', 'lemme': 'un', 'classgr': 'DET'}, {'id': '2', 'forme': 'fois', 'lemme': 'fois', 'classgr': 'NOUN'}, {'id': '3', 'forme': 'de', 'lemme': 'de', 'classgr': 'ADP'}, {'id': '4', 'forme': 'plus', 'lemme': 'plus', 'classgr': 'ADV'}, {'id': '5', 'forme': 'je', 'lemme': 'moi', 'classgr': 'PRON'}, {'id': '6', 'forme': 'répète', 'lemme': 'répéter', 'classgr': 'VERB'}, {'id': '7', 'forme': ':', 'lemme': ':', 'classgr': 'PUNCT'}, {'id': '8', 'forme': 'Clarence', 'lemme': 'Clarence', 'classgr': 'PROPN'}, {'id': '9', 'forme': 'étais', 'lemme': 'être', 'classgr': 'AUX'}, {'id': '10', 'forme': 'lumineux', 'lemme': 'lumineux', 'classgr': 'ADJ'}, {'id': '11', 'forme': '.', 'lemme': '.', 'classgr': 'PUNCT'}]]\n",
            "Taille minimale des n-grammes: 2\n",
            "Taille maximale des n-grammes: 3\n",
            "Les statistiques ont été enregistrées dans le fichier statistiques.json\n"
          ]
        }
      ],
      "source": [
        "\n",
        "try:\n",
        "\n",
        "    with open(\"statistiques.json\", \"w\", encoding=\"utf-8\") as fichier:\n",
        "        json.dump(statistiques(lire_conllu(\"source.conllu\")), fichier, ensure_ascii=False)\n",
        "    print(\"Les statistiques ont été enregistrées dans le fichier statistiques.json\")\n",
        "\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Le fichier source.conllu n'a pas été trouvé.\")\n",
        "except Exception as e:\n",
        "    print(f\"Une erreur s'est produite : {e}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}